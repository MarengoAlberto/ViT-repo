{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "APP_NAME = 'ViT-model'\n",
    "MODEL_PT_FILEPATH = 'saved_models/VisionTransformers'\n",
    "MAR_MODEL_OUT_PATH = 'serve'\n",
    "handler = 'predictor/handler.py'\n",
    "MODEL_DISPLAY_NAME = 'ViT-model'\n",
    "model_version = 1\n",
    "PROJECT_ID = 'alberto-playground'\n",
    "BUCKET_NAME = 'alberto-vit-playground'\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_vit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # create directory to save model archive file\n",
    "# model_output_root = MODEL_PT_FILEPATH\n",
    "# mar_output_root = MAR_MODEL_OUT_PATH\n",
    "# additiona_files_base_dir = 'src/model'\n",
    "# export_path = f\"{mar_output_root}/model-store\"\n",
    "# try:\n",
    "#     Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "# except Exception as e:\n",
    "#     logging.warning(e)\n",
    "#     # retry after pause\n",
    "#     time.sleep(2)\n",
    "#     Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "#\n",
    "# # parse and configure paths for model archive config\n",
    "# handler_path = (\n",
    "#     handler.replace(\"gs://\", \"/gcs/\") + \"predictor/handler.py\"\n",
    "#     if handler.startswith(\"gs://\")\n",
    "#     else handler\n",
    "# )\n",
    "# model_artifacts_dir = model_output_root\n",
    "# extra_files = [\n",
    "#     os.path.join(additiona_files_base_dir, f)\n",
    "#     for f in os.listdir(additiona_files_base_dir)]\n",
    "#\n",
    "# # define model archive config\n",
    "# mar_config = {\n",
    "#     \"MODEL_NAME\": MODEL_DISPLAY_NAME,\n",
    "#     \"HANDLER\": handler_path,\n",
    "#     \"SERIALIZED_FILE\": f'{model_artifacts_dir}/ViT.pt',\n",
    "#     \"VERSION\": model_version,\n",
    "#     \"EXTRA_FILES\": \",\".join(extra_files),\n",
    "#     \"EXPORT_PATH\": export_path,\n",
    "# }\n",
    "#\n",
    "# # generate model archive command\n",
    "# archiver_cmd = (\n",
    "#     \"torch-model-archiver --force \"\n",
    "#     f\"--model-name {mar_config['MODEL_NAME']} \"\n",
    "#     f\"--serialized-file {mar_config['SERIALIZED_FILE']} \"\n",
    "#     f\"--handler {mar_config['HANDLER']} \"\n",
    "#     f\"--version {mar_config['VERSION']}\"\n",
    "# )\n",
    "# if \"EXPORT_PATH\" in mar_config:\n",
    "#     archiver_cmd += f\" --export-path {mar_config['EXPORT_PATH']}\"\n",
    "# if \"EXTRA_FILES\" in mar_config:\n",
    "#     archiver_cmd += f\" --extra-files {mar_config['EXTRA_FILES']}\"\n",
    "# if \"REQUIREMENTS_FILE\" in mar_config:\n",
    "#     archiver_cmd += f\" --requirements-file {mar_config['REQUIREMENTS_FILE']}\"\n",
    "#\n",
    "# # run archiver command\n",
    "# logging.warning(\"Running archiver command: %s\", archiver_cmd)\n",
    "# with subprocess.Popen(\n",
    "#         archiver_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "# ) as p:\n",
    "#     _, err = p.communicate()\n",
    "#     if err:\n",
    "#         raise ValueError(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Client().bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(f'{MAR_MODEL_OUT_PATH}/ViT-model.mar')\n",
    "blob.upload_from_filename('serve/model-store/ViT-model.mar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  394.5MB\n",
      "Step 1/21 : FROM pytorch/torchserve:latest-cpu\n",
      " ---> 68a3fcae81af\n",
      "Step 2/21 : USER root\n",
      " ---> Using cache\n",
      " ---> 74b7dbf2b479\n",
      "Step 3/21 : RUN apt-get update &&     apt-get install -y software-properties-common &&     add-apt-repository -y ppa:ubuntu-toolchain-r/test &&     apt-get update &&     apt-get install -y gcc-9 g++-9 apt-transport-https ca-certificates gnupg curl\n",
      " ---> Using cache\n",
      " ---> 6e360930db3d\n",
      "Step 4/21 : RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" |     tee -a /etc/apt/sources.list.d/google-cloud-sdk.list &&     curl https://packages.cloud.google.com/apt/doc/apt-key.gpg |     apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - &&     apt-get update -y &&     apt-get install google-cloud-sdk -y\n",
      " ---> Using cache\n",
      " ---> bfe0359200e4\n",
      "Step 5/21 : USER model-server\n",
      " ---> Using cache\n",
      " ---> 2d2bde191019\n",
      "Step 6/21 : RUN python3 -m pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 37c9ec098c4f\n",
      "Step 7/21 : COPY serve/model-store/ViT-model.mar /home/model-server/model-store/\n",
      " ---> e603564cf5fa\n",
      "Step 8/21 : ARG MODEL_NAME=ViT-model\n",
      " ---> Running in 24b22668192d\n",
      "Removing intermediate container 24b22668192d\n",
      " ---> 4322dd66cf30\n",
      "Step 9/21 : ENV MODEL_NAME=\"${MODEL_NAME}\"\n",
      " ---> Running in 85b09aa49d00\n",
      "Removing intermediate container 85b09aa49d00\n",
      " ---> 84a5ca4de890\n",
      "Step 10/21 : ARG MAR_URI=gs://alberto-playground/serve\n",
      " ---> Running in b6cbafb2654c\n",
      "Removing intermediate container b6cbafb2654c\n",
      " ---> 73bbb03114ac\n",
      "Step 11/21 : ENV MAR_URI=\"${AIP_STORAGE_URI}\"\n",
      " ---> Running in 4f6c64bccd6f\n",
      "Removing intermediate container 4f6c64bccd6f\n",
      " ---> ecf797ca2e0d\n",
      "Step 12/21 : ARG AIP_HTTP_PORT=7080\n",
      " ---> Running in 60243e6d1846\n",
      "Removing intermediate container 60243e6d1846\n",
      " ---> e897495c6135\n",
      "Step 13/21 : ENV AIP_HTTP_PORT=\"${AIP_HTTP_PORT}\"\n",
      " ---> Running in 13b8047e03c7\n",
      "Removing intermediate container 13b8047e03c7\n",
      " ---> ae2f576e2b7c\n",
      "Step 14/21 : ARG MODEL_MGMT_PORT=7081\n",
      " ---> Running in 39557516cb66\n",
      "Removing intermediate container 39557516cb66\n",
      " ---> 95d5794e680e\n",
      "Step 15/21 : EXPOSE \"${AIP_HTTP_PORT}\"\n",
      " ---> Running in 287c16e77b7f\n",
      "Removing intermediate container 287c16e77b7f\n",
      " ---> 26f8ca427fee\n",
      "Step 16/21 : EXPOSE \"${MODEL_MGMT_PORT}\"\n",
      " ---> Running in 24799982ba71\n",
      "Removing intermediate container 24799982ba71\n",
      " ---> 6f3343fbad7d\n",
      "Step 17/21 : EXPOSE 8080 8081 8082 7070 7071\n",
      " ---> Running in 3e5c9a3ef40b\n",
      "Removing intermediate container 3e5c9a3ef40b\n",
      " ---> 37374f5acb81\n",
      "Step 18/21 : USER root\n",
      " ---> Running in f58ba7c823e5\n",
      "Removing intermediate container f58ba7c823e5\n",
      " ---> 3b14fbd90d0a\n",
      "Step 19/21 : RUN echo \"service_envelope=json\\n\"     \"inference_address=http://0.0.0.0:${AIP_HTTP_PORT}\\n\"     \"management_address=http://0.0.0.0:${MODEL_MGMT_PORT}\" >>     /home/model-server/config.properties\n",
      " ---> Running in cb4ca982544f\n",
      "Removing intermediate container cb4ca982544f\n",
      " ---> 2b42bd8eb80e\n",
      "Step 20/21 : USER model-server\n",
      " ---> Running in f95fd7af74b2\n",
      "Removing intermediate container f95fd7af74b2\n",
      " ---> a582e7c9b3fb\n",
      "Step 21/21 : CMD [\"echo\", \"MAR_URI=${MAR_URI}\", \";\",    \"ls\", \"-ltr\", \"/home/model-server/model-store/\", \";\",     \"torchserve\", \"--start\", \"--ts-config=/home/model-server/config.properties\",     \"--models\", \"${MODEL_NAME}=${MODEL_NAME}.mar\",     \"--model-store\", \"/home/model-server/model-store\"]\n",
      " ---> Running in 6953e89134c8\n",
      "Removing intermediate container 6953e89134c8\n",
      " ---> cb96b099a916\n",
      "Successfully built cb96b099a916\n",
      "Successfully tagged gcr.io/alberto-playground/pytorch_predict_vit:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -f predictor/Dockerfile -t $CUSTOM_PREDICTOR_IMAGE_URI ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/alberto-playground/pytorch_predict_vit]\n",
      "\n",
      "\u001B[1Bdab534e6: Preparing \n",
      "\u001B[1B910d1d41: Preparing \n",
      "\u001B[1Be1b71f7f: Preparing \n",
      "\u001B[1B7b334d17: Preparing \n",
      "\u001B[1B001bafce: Preparing \n",
      "\u001B[1Bbf18a086: Preparing \n",
      "\u001B[1B7cf25f52: Preparing \n",
      "\u001B[1Bfa8107fa: Preparing \n",
      "\u001B[1B24bd1a34: Preparing \n",
      "\u001B[1B0b544b4c: Preparing \n",
      "\u001B[1B613e1d99: Preparing \n",
      "\u001B[1Bb3c8b2c4: Preparing \n",
      "\u001B[1B0ae33361: Preparing \n",
      "\u001B[13B10d1d41: Pushed   11.69MB/11.68MB\u001B[2K\u001B[10A\u001B[2K\u001B[13A\u001B[2K\u001B[8A\u001B[2K\u001B[13A\u001B[2K\u001B[4A\u001B[2K\u001B[13A\u001B[2K\u001B[13A\u001B[2K\u001B[13A\u001B[2K\u001B[14A\u001B[2K\u001B[13A\u001B[2Klatest: digest: sha256:5da4c37a2c66a080be8c210cb9ed514deb75d4de5847a54aaa02b69b31d27860 size: 3253\n"
     ]
    }
   ],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_display_name = f\"{APP_NAME}-v{model_version}\"\n",
    "model_description = \"PyTorch Image classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/634066980332/locations/us-central1/models/5377220989266427904/operations/1417860582349996032\n",
      "Model created. Resource name: projects/634066980332/locations/us-central1/models/5377220989266427904@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/634066980332/locations/us-central1/models/5377220989266427904@1')\n",
      "ViT-model-v1\n",
      "projects/634066980332/locations/us-central1/models/5377220989266427904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    "    artifact_uri=f'gs://{BUCKET_NAME}/{MAR_MODEL_OUT_PATH}',\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/634066980332/locations/us-central1/endpoints/8755274752538443776/operations/768779286055223296\n",
      "Endpoint created. Resource name: projects/634066980332/locations/us-central1/endpoints/8755274752538443776\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/634066980332/locations/us-central1/endpoints/8755274752538443776')\n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/634066980332/locations/us-central1/endpoints/8755274752538443776\n",
      "Deploy Endpoint model backing LRO: projects/634066980332/locations/us-central1/endpoints/8755274752538443776/operations/1881168394015735808\n",
      "Endpoint model deployed. Resource name: projects/634066980332/locations/us-central1/endpoints/8755274752538443776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f8e63486fb0> \n",
       "resource name: projects/634066980332/locations/us-central1/endpoints/8755274752538443776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint display name = ViT-model-endpoint resource id =projects/634066980332/locations/us-central1/endpoints/8755274752538443776 \n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"945036841143238656\"\n",
       " model: \"projects/634066980332/locations/us-central1/models/5377220989266427904\"\n",
       " display_name: \"ViT-model-v1\"\n",
       " create_time {\n",
       "   seconds: 1690648838\n",
       "   nanos: 485629000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_img_size(img, target_filesize, tolerance=5):\n",
    "    # img = img_orig = Image.open(img_filename)\n",
    "    aspect = img.size[0] / img.size[1]\n",
    "\n",
    "    while True:\n",
    "        with BytesIO() as buffer:\n",
    "            img.save(buffer, format=\"JPEG\")\n",
    "            data = buffer.getvalue()\n",
    "        filesize = len(data)    \n",
    "        size_deviation = filesize / target_filesize\n",
    "        print(\"size: {}; factor: {:.3f}\".format(filesize, size_deviation))\n",
    "\n",
    "        if size_deviation <= (100 + tolerance) / 100:\n",
    "            # filesize fits\n",
    "            return data\n",
    "        else:\n",
    "            # filesize not good enough => adapt width and height\n",
    "            # use sqrt of deviation since applied both in width and height\n",
    "            new_width = img.size[0] / size_deviation**0.5    \n",
    "            new_height = new_width / aspect\n",
    "            # resize from img_orig to not lose quality\n",
    "            img = img.resize((int(new_width), int(new_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 281851; factor: 18.790\n",
      "size: 17194; factor: 1.146\n",
      "size: 14442; factor: 0.963\n"
     ]
    }
   ],
   "source": [
    "blob = bucket.get_blob('samples/pexels-helena-lopes-1996332.jpg')    \n",
    "img = Image.open(BytesIO(blob.download_as_bytes()))\n",
    "image_bytes = limit_img_size(img,  15000,tolerance = 5)\n",
    "encoded_string = base64.b64encode(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = [{\"body\": \n",
    "    {\n",
    "    \"file\": {\n",
    "        \"filename\": \"pexels-helena-lopes-1996332.jpg\",\n",
    "        \"content\": f\"{str(encoded_string.decode('utf-8'))}\" }\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'probabilities': {'truck': 0.02285150066018105, 'horse': 0.09804531931877136, 'deer': 0.06153243407607079, 'bird': 0.06922928243875504, 'frog': 0.1282880455255508, 'automobile': 0.07853943854570389, 'dog': 0.1819493472576141, 'cat': 0.06561080366373062, 'ship': 0.1539709866046906, 'airplane': 0.1399828493595123}, 'response': 'dog'}], deployed_model_id='945036841143238656', model_version_id='1', model_resource_name='projects/634066980332/locations/us-central1/models/5377220989266427904', explanations=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
