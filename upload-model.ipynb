{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "APP_NAME = 'ViT-model'\n",
    "MODEL_PT_FILEPATH = 'saved_models/VisionTransformers'\n",
    "MAR_MODEL_OUT_PATH = 'serve'\n",
    "handler = 'predictor/handler.py'\n",
    "MODEL_DISPLAY_NAME = 'ViT-model'\n",
    "model_version = 1\n",
    "PROJECT_ID = 'alberto-playground'\n",
    "BUCKET_NAME = 'alberto-vit-playground'\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_vit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # create directory to save model archive file\n",
    "# model_output_root = MODEL_PT_FILEPATH\n",
    "# mar_output_root = MAR_MODEL_OUT_PATH\n",
    "# additiona_files_base_dir = 'src/model'\n",
    "# export_path = f\"{mar_output_root}/model-store\"\n",
    "# try:\n",
    "#     Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "# except Exception as e:\n",
    "#     logging.warning(e)\n",
    "#     # retry after pause\n",
    "#     time.sleep(2)\n",
    "#     Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "#\n",
    "# # parse and configure paths for model archive config\n",
    "# handler_path = (\n",
    "#     handler.replace(\"gs://\", \"/gcs/\") + \"predictor/handler.py\"\n",
    "#     if handler.startswith(\"gs://\")\n",
    "#     else handler\n",
    "# )\n",
    "# model_artifacts_dir = model_output_root\n",
    "# extra_files = [\n",
    "#     os.path.join(additiona_files_base_dir, f)\n",
    "#     for f in os.listdir(additiona_files_base_dir)]\n",
    "#\n",
    "# # define model archive config\n",
    "# mar_config = {\n",
    "#     \"MODEL_NAME\": MODEL_DISPLAY_NAME,\n",
    "#     \"HANDLER\": handler_path,\n",
    "#     \"SERIALIZED_FILE\": f'{model_artifacts_dir}/ViT.pt',\n",
    "#     \"VERSION\": model_version,\n",
    "#     \"EXTRA_FILES\": \",\".join(extra_files),\n",
    "#     \"EXPORT_PATH\": export_path,\n",
    "# }\n",
    "#\n",
    "# # generate model archive command\n",
    "# archiver_cmd = (\n",
    "#     \"torch-model-archiver --force \"\n",
    "#     f\"--model-name {mar_config['MODEL_NAME']} \"\n",
    "#     f\"--serialized-file {mar_config['SERIALIZED_FILE']} \"\n",
    "#     f\"--handler {mar_config['HANDLER']} \"\n",
    "#     f\"--version {mar_config['VERSION']}\"\n",
    "# )\n",
    "# if \"EXPORT_PATH\" in mar_config:\n",
    "#     archiver_cmd += f\" --export-path {mar_config['EXPORT_PATH']}\"\n",
    "# if \"EXTRA_FILES\" in mar_config:\n",
    "#     archiver_cmd += f\" --extra-files {mar_config['EXTRA_FILES']}\"\n",
    "# if \"REQUIREMENTS_FILE\" in mar_config:\n",
    "#     archiver_cmd += f\" --requirements-file {mar_config['REQUIREMENTS_FILE']}\"\n",
    "#\n",
    "# # run archiver command\n",
    "# logging.warning(\"Running archiver command: %s\", archiver_cmd)\n",
    "# with subprocess.Popen(\n",
    "#         archiver_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "# ) as p:\n",
    "#     _, err = p.communicate()\n",
    "#     if err:\n",
    "#         raise ValueError(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Client().bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(f'{MAR_MODEL_OUT_PATH}/ViT-model.mar')\n",
    "blob.upload_from_filename('serve/model-store/ViT-model.mar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  394.6MB\n",
      "Step 1/24 : FROM pytorch/torchserve:latest-cpu\n",
      " ---> 68a3fcae81af\n",
      "Step 2/24 : USER root\n",
      " ---> Using cache\n",
      " ---> 74b7dbf2b479\n",
      "Step 3/24 : RUN apt-get update &&     apt-get install -y software-properties-common &&     add-apt-repository -y ppa:ubuntu-toolchain-r/test &&     apt-get update &&     apt-get install -y gcc-9 g++-9 apt-transport-https ca-certificates gnupg curl\n",
      " ---> Using cache\n",
      " ---> 6e360930db3d\n",
      "Step 4/24 : RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" |     tee -a /etc/apt/sources.list.d/google-cloud-sdk.list &&     curl https://packages.cloud.google.com/apt/doc/apt-key.gpg |     apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - &&     apt-get update -y &&     apt-get install google-cloud-sdk -y\n",
      " ---> Using cache\n",
      " ---> bfe0359200e4\n",
      "Step 5/24 : USER model-server\n",
      " ---> Using cache\n",
      " ---> 2d2bde191019\n",
      "Step 6/24 : RUN python3 -m pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 37c9ec098c4f\n",
      "Step 7/24 : RUN python3 -m pip install google-cloud-storage\n",
      " ---> Using cache\n",
      " ---> 1466c1a67496\n",
      "Step 8/24 : COPY serve/model-store/ViT-model.mar /home/model-server/model-store/\n",
      " ---> c6d67c5ea728\n",
      "Step 9/24 : COPY token/alberto-playground-bc631f2fcabd.json /home/model-server/\n",
      " ---> 1bd036e8977c\n",
      "Step 10/24 : ENV GOOGLE_APPLICATION_CREDENTIALS=/home/model-server/alberto-playground-bc631f2fcabd.json\n",
      " ---> Running in 2db8ba4df14e\n",
      "Removing intermediate container 2db8ba4df14e\n",
      " ---> 84f1c413ee13\n",
      "Step 11/24 : ARG MODEL_NAME=ViT-model\n",
      " ---> Running in d716a9b57bdf\n",
      "Removing intermediate container d716a9b57bdf\n",
      " ---> 983e7fbc33fa\n",
      "Step 12/24 : ENV MODEL_NAME=\"${MODEL_NAME}\"\n",
      " ---> Running in d7daadcaf6f3\n",
      "Removing intermediate container d7daadcaf6f3\n",
      " ---> b042b3aa861d\n",
      "Step 13/24 : ARG MAR_URI=gs://alberto-playground/serve\n",
      " ---> Running in 73fc5483e5d3\n",
      "Removing intermediate container 73fc5483e5d3\n",
      " ---> a68242f0d2c2\n",
      "Step 14/24 : ENV MAR_URI=\"${AIP_STORAGE_URI}\"\n",
      " ---> Running in 79bee271d5bc\n",
      "Removing intermediate container 79bee271d5bc\n",
      " ---> 146c4798e846\n",
      "Step 15/24 : ARG AIP_HTTP_PORT=7080\n",
      " ---> Running in ae901e7659d6\n",
      "Removing intermediate container ae901e7659d6\n",
      " ---> 0d3576895d6d\n",
      "Step 16/24 : ENV AIP_HTTP_PORT=\"${AIP_HTTP_PORT}\"\n",
      " ---> Running in 25884499861f\n",
      "Removing intermediate container 25884499861f\n",
      " ---> b2a3bddf8345\n",
      "Step 17/24 : ARG MODEL_MGMT_PORT=7081\n",
      " ---> Running in 3fe043ba7680\n",
      "Removing intermediate container 3fe043ba7680\n",
      " ---> c6552d64dced\n",
      "Step 18/24 : EXPOSE \"${AIP_HTTP_PORT}\"\n",
      " ---> Running in f95c52ef408c\n",
      "Removing intermediate container f95c52ef408c\n",
      " ---> fb6b90e14e1e\n",
      "Step 19/24 : EXPOSE \"${MODEL_MGMT_PORT}\"\n",
      " ---> Running in 9350231ee2fb\n",
      "Removing intermediate container 9350231ee2fb\n",
      " ---> e3bc3b9fe3a7\n",
      "Step 20/24 : EXPOSE 8080 8081 8082 7070 7071\n",
      " ---> Running in b578434a4a4e\n",
      "Removing intermediate container b578434a4a4e\n",
      " ---> 287cc4283e91\n",
      "Step 21/24 : USER root\n",
      " ---> Running in 70432539beb8\n",
      "Removing intermediate container 70432539beb8\n",
      " ---> 3301d62bee84\n",
      "Step 22/24 : RUN echo \"service_envelope=json\\n\"     \"inference_address=http://0.0.0.0:${AIP_HTTP_PORT}\\n\"     \"management_address=http://0.0.0.0:${MODEL_MGMT_PORT}\" >>     /home/model-server/config.properties\n",
      " ---> Running in 4233fc339b97\n",
      "Removing intermediate container 4233fc339b97\n",
      " ---> ebe14aeef143\n",
      "Step 23/24 : USER model-server\n",
      " ---> Running in fd1c7eb50525\n",
      "Removing intermediate container fd1c7eb50525\n",
      " ---> 375bf3cb7906\n",
      "Step 24/24 : CMD [\"echo\", \"MAR_URI=${MAR_URI}\", \";\",    \"ls\", \"-ltr\", \"/home/model-server/model-store/\", \";\",     \"torchserve\", \"--start\", \"--ts-config=/home/model-server/config.properties\",     \"--models\", \"${MODEL_NAME}=${MODEL_NAME}.mar\",     \"--model-store\", \"/home/model-server/model-store\"]\n",
      " ---> Running in 74eb68b7d9bc\n",
      "Removing intermediate container 74eb68b7d9bc\n",
      " ---> 10a058ab9bb8\n",
      "Successfully built 10a058ab9bb8\n",
      "Successfully tagged gcr.io/alberto-playground/pytorch_predict_vit:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -f predictor/Dockerfile -t $CUSTOM_PREDICTOR_IMAGE_URI ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/alberto-playground/pytorch_predict_vit]\n",
      "\n",
      "\u001B[1Bd321a13c: Preparing \n",
      "\u001B[1B6e639786: Preparing \n",
      "\u001B[1Bca3ba6bc: Preparing \n",
      "\u001B[1Bb3e72f47: Preparing \n",
      "\u001B[1Be1b71f7f: Preparing \n",
      "\u001B[1B7b334d17: Preparing \n",
      "\u001B[1B001bafce: Preparing \n",
      "\u001B[1Bbf18a086: Preparing \n",
      "\u001B[1B7cf25f52: Preparing \n",
      "\u001B[1Bfa8107fa: Preparing \n",
      "\u001B[1B24bd1a34: Preparing \n",
      "\u001B[1B0b544b4c: Preparing \n",
      "\u001B[1B613e1d99: Preparing \n",
      "\u001B[1Bb3c8b2c4: Preparing \n",
      "\u001B[1B0ae33361: Preparing \n",
      "\u001B[14Ba3ba6bc: Pushed   11.69MB/11.68MB\u001B[11A\u001B[2K\u001B[9A\u001B[2K\u001B[6A\u001B[2K\u001B[14A\u001B[2K\u001B[2A\u001B[2K\u001B[14A\u001B[2K\u001B[14A\u001B[2K\u001B[14A\u001B[2K\u001B[16A\u001B[2K\u001B[15A\u001B[2K\u001B[14A\u001B[2Klatest: digest: sha256:583ce1a37e1819f95d2ff0351eccd9ed65dc44813938114456b6058eb70706e2 size: 3672\n"
     ]
    }
   ],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_display_name = f\"{APP_NAME}-v{model_version}\"\n",
    "model_description = \"PyTorch Image classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/634066980332/locations/us-central1/models/7447399074229125120/operations/9194591976400355328\n",
      "Model created. Resource name: projects/634066980332/locations/us-central1/models/7447399074229125120@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/634066980332/locations/us-central1/models/7447399074229125120@1')\n",
      "ViT-model-v1\n",
      "projects/634066980332/locations/us-central1/models/7447399074229125120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    "    artifact_uri=f'gs://{BUCKET_NAME}/{MAR_MODEL_OUT_PATH}',\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/634066980332/locations/us-central1/endpoints/3103257220188471296/operations/6071345634818916352\n",
      "Endpoint created. Resource name: projects/634066980332/locations/us-central1/endpoints/3103257220188471296\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/634066980332/locations/us-central1/endpoints/3103257220188471296')\n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/634066980332/locations/us-central1/endpoints/3103257220188471296\n",
      "Deploy Endpoint model backing LRO: projects/634066980332/locations/us-central1/endpoints/3103257220188471296/operations/8654160021115895808\n",
      "Endpoint model deployed. Resource name: projects/634066980332/locations/us-central1/endpoints/3103257220188471296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f9575fd7e20> \n",
       "resource name: projects/634066980332/locations/us-central1/endpoints/3103257220188471296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint display name = ViT-model-endpoint resource id =projects/634066980332/locations/us-central1/endpoints/3103257220188471296 \n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"5802731989215739904\"\n",
       " model: \"projects/634066980332/locations/us-central1/models/7447399074229125120\"\n",
       " display_name: \"ViT-model-v1\"\n",
       " create_time {\n",
       "   seconds: 1690692433\n",
       "   nanos: 646750000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_img_size(img, target_filesize, tolerance=5):\n",
    "    # img = img_orig = Image.open(img_filename)\n",
    "    aspect = img.size[0] / img.size[1]\n",
    "\n",
    "    while True:\n",
    "        with BytesIO() as buffer:\n",
    "            img.save(buffer, format=\"JPEG\")\n",
    "            data = buffer.getvalue()\n",
    "        filesize = len(data)    \n",
    "        size_deviation = filesize / target_filesize\n",
    "        print(\"size: {}; factor: {:.3f}\".format(filesize, size_deviation))\n",
    "\n",
    "        if size_deviation <= (100 + tolerance) / 100:\n",
    "            # filesize fits\n",
    "            return data\n",
    "        else:\n",
    "            # filesize not good enough => adapt width and height\n",
    "            # use sqrt of deviation since applied both in width and height\n",
    "            new_width = img.size[0] / size_deviation**0.5    \n",
    "            new_height = new_width / aspect\n",
    "            # resize from img_orig to not lose quality\n",
    "            img = img.resize((int(new_width), int(new_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 281851; factor: 18.790\n",
      "size: 17194; factor: 1.146\n",
      "size: 14442; factor: 0.963\n"
     ]
    }
   ],
   "source": [
    "blob = bucket.get_blob('samples/pexels-helena-lopes-1996332.jpg')    \n",
    "img = Image.open(BytesIO(blob.download_as_bytes()))\n",
    "image_bytes = limit_img_size(img,  15000,tolerance = 5)\n",
    "encoded_string = base64.b64encode(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = [\n",
    "    {\n",
    "    \"file\": {\n",
    "        \"filename\": \"pexels-helena-lopes-1996332.jpg\",\n",
    "        \"content\": f\"{str(encoded_string.decode('utf-8'))}\" }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'response': 'dog', 'probabilities': {'cat': 0.06561080366373062, 'ship': 0.1539709866046906, 'dog': 0.1819493472576141, 'frog': 0.1282880455255508, 'deer': 0.06153243407607079, 'automobile': 0.07853943854570389, 'bird': 0.06922928243875504, 'horse': 0.09804531931877136, 'airplane': 0.1399828493595123, 'truck': 0.02285150066018105}}], deployed_model_id='5802731989215739904', model_version_id='1', model_resource_name='projects/634066980332/locations/us-central1/models/7447399074229125120', explanations=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = [{'link': 'gs://alberto-vit-playground/samples/pexels-helena-lopes-1996332.jpg'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'response': 'dog', 'probabilities': {'cat': 0.06622505933046341, 'dog': 0.18122299015522, 'airplane': 0.1400623470544815, 'truck': 0.02236789651215076, 'frog': 0.1266641616821289, 'deer': 0.06160113960504532, 'ship': 0.1543110311031342, 'horse': 0.0966719463467598, 'bird': 0.07047797739505768, 'automobile': 0.08039550483226776}}], deployed_model_id='5802731989215739904', model_version_id='1', model_resource_name='projects/634066980332/locations/us-central1/models/7447399074229125120', explanations=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
