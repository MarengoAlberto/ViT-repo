{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "APP_NAME = 'ViT-model'\n",
    "MODEL_PT_FILEPATH = 'saved_models/VisionTransformers'\n",
    "MAR_MODEL_OUT_PATH = 'serve'\n",
    "handler = 'predictor/handler.py'\n",
    "MODEL_DISPLAY_NAME = 'ViT-model'\n",
    "model_version = 1\n",
    "PROJECT_ID = 'alberto-playground'\n",
    "BUCKET_NAME = 'alberto-vit-playground'\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_vit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint display name = ViT-model-endpoint resource id =projects/634066980332/locations/us-central1/endpoints/8755274752538443776 \n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"945036841143238656\"\n",
       " model: \"projects/634066980332/locations/us-central1/models/5377220989266427904\"\n",
       " display_name: \"ViT-model-v1\"\n",
       " create_time {\n",
       "   seconds: 1690648838\n",
       "   nanos: 485629000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_img_size(img, target_filesize, tolerance=5):\n",
    "    # img = img_orig = Image.open(img_filename)\n",
    "    aspect = img.size[0] / img.size[1]\n",
    "\n",
    "    while True:\n",
    "        with BytesIO() as buffer:\n",
    "            img.save(buffer, format=\"JPEG\")\n",
    "            data = buffer.getvalue()\n",
    "        filesize = len(data)    \n",
    "        size_deviation = filesize / target_filesize\n",
    "        print(\"size: {}; factor: {:.3f}\".format(filesize, size_deviation))\n",
    "\n",
    "        if size_deviation <= (100 + tolerance) / 100:\n",
    "            # filesize fits\n",
    "            return data\n",
    "        else:\n",
    "            # filesize not good enough => adapt width and height\n",
    "            # use sqrt of deviation since applied both in width and height\n",
    "            new_width = img.size[0] / size_deviation**0.5    \n",
    "            new_height = new_width / aspect\n",
    "            # resize from img_orig to not lose quality\n",
    "            img = img.resize((int(new_width), int(new_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 281851; factor: 18.790\n",
      "size: 17194; factor: 1.146\n",
      "size: 14442; factor: 0.963\n"
     ]
    }
   ],
   "source": [
    "bucket = storage.Client().bucket(BUCKET_NAME)\n",
    "blob = bucket.get_blob('samples/pexels-helena-lopes-1996332.jpg')    \n",
    "img = Image.open(BytesIO(blob.download_as_bytes()))\n",
    "image_bytes = limit_img_size(img,  15000,tolerance = 5)\n",
    "encoded_string = base64.b64encode(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = [{\"body\": \n",
    "    {\n",
    "    \"file\": {\n",
    "        \"filename\": \"pexels-helena-lopes-1996332.jpg\",\n",
    "        \"content\": f\"{str(encoded_string.decode('utf-8'))}\" }\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'probabilities': {'airplane': 0.1399828493595123, 'ship': 0.1539709866046906, 'truck': 0.02285150066018105, 'cat': 0.06561080366373062, 'dog': 0.1819493472576141, 'automobile': 0.07853943854570389, 'deer': 0.06153243407607079, 'frog': 0.1282880455255508, 'horse': 0.09804531931877136, 'bird': 0.06922928243875504}, 'response': 'dog'}], deployed_model_id='945036841143238656', model_version_id='1', model_resource_name='projects/634066980332/locations/us-central1/models/5377220989266427904', explanations=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
