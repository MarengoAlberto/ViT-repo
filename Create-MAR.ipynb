{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "APP_NAME = 'ViT'\n",
    "MODEL_PT_FILEPATH = ''\n",
    "MAR_MODEL_OUT_PATH = ''\n",
    "handler = ''\n",
    "MODEL_DISPLAY_NAME = 'Vit-model'\n",
    "model_version = 1\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = ''\n",
    "PROJECT_ID = ''\n",
    "BUCKET_NAME = ''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create directory to save model archive file\n",
    "model_output_root = MODEL_PT_FILEPATH\n",
    "mar_output_root = MAR_MODEL_OUT_PATH\n",
    "export_path = f\"{mar_output_root}/model-store\"\n",
    "try:\n",
    "    Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "except Exception as e:\n",
    "    logging.warning(e)\n",
    "    # retry after pause\n",
    "    time.sleep(2)\n",
    "    Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# parse and configure paths for model archive config\n",
    "handler_path = (\n",
    "    handler.replace(\"gs://\", \"/gcs/\") + \"predictor/handler.py\"\n",
    "    if handler.startswith(\"gs://\")\n",
    "    else handler\n",
    ")\n",
    "model_artifacts_dir = f\"{model_output_root}/model/{MODEL_DISPLAY_NAME}\"\n",
    "\n",
    "\n",
    "# define model archive config\n",
    "mar_config = {\n",
    "    \"MODEL_NAME\": MODEL_DISPLAY_NAME,\n",
    "    \"HANDLER\": handler_path,\n",
    "    \"SERIALIZED_FILE\": f\"{model_artifacts_dir}/ViT.pt\",\n",
    "    \"VERSION\": model_version,\n",
    "    \"EXPORT_PATH\": f\"{MAR_MODEL_OUT_PATH}/model-store\",\n",
    "}\n",
    "\n",
    "# generate model archive command\n",
    "archiver_cmd = (\n",
    "    \"torch-model-archiver --force \"\n",
    "    f\"--model-name {mar_config['MODEL_NAME']} \"\n",
    "    f\"--serialized-file {mar_config['SERIALIZED_FILE']} \"\n",
    "    f\"--handler {mar_config['HANDLER']} \"\n",
    "    f\"--version {mar_config['VERSION']}\"\n",
    ")\n",
    "if \"EXPORT_PATH\" in mar_config:\n",
    "    archiver_cmd += f\" --export-path {mar_config['EXPORT_PATH']}\"\n",
    "if \"EXTRA_FILES\" in mar_config:\n",
    "    archiver_cmd += f\" --extra-files {mar_config['EXTRA_FILES']}\"\n",
    "if \"REQUIREMENTS_FILE\" in mar_config:\n",
    "    archiver_cmd += f\" --requirements-file {mar_config['REQUIREMENTS_FILE']}\"\n",
    "\n",
    "# run archiver command\n",
    "logging.warning(\"Running archiver command: %s\", archiver_cmd)\n",
    "with subprocess.Popen(\n",
    "        archiver_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    ") as p:\n",
    "    _, err = p.communicate()\n",
    "    if err:\n",
    "        raise ValueError(err)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!docker build --tag=$CUSTOM_PREDICTOR_IMAGE_URI ./predictor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_display_name = f\"{APP_NAME}-v{model_version}\"\n",
    "model_description = \"PyTorch based text classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint.list_models()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_images = ''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "for image in test_images:\n",
    "    print(f\"Formatted input: \\n{json.dumps(image, indent=4)}\\n\")\n",
    "    prediction = endpoint.predict(instances=image)\n",
    "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
