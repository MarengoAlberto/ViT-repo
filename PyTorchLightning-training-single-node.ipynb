{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) TPU configuration\n",
    "\n",
    "To use [Cloud TPUs](https://cloud.google.com/tpu), first create a [TPU node](https://cloud.google.com/tpu/docs/creating-deleting-tpus#setup_TPU_only). Set the **TPU software version** to a matching PyTorch version (e.g. `pytorch-1.7`) and the **Network** to the same network used for your notebook instance (e.g. `datalab-network`).\n",
    "\n",
    "Uncomment this section only if you are using TPUs. Note that you must be running this notebook on an [XLA](https://github.com/pytorch/xla) image such as [pytorch-xla.1-7](gcr.io/deeplearning-platform-release/pytorch-xla.1-7) for PyTorch to connect to Cloud TPUs. To use an XLA image, you can create a new notebook instance with the **Environment** set to `Custom container` and the **Docker container image** set to the XLA image location.\n",
    "\n",
    "If you need a quota increase for Cloud TPUs, please review the [Cloud TPU Quota Policy](https://cloud.google.com/tpu/docs/quota) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review TPU configuration\n",
    "\n",
    "Run the gcloud command to review the available TPUs for the one you wish to use.\n",
    "Make note of the IP address (from NETWORK_ENDPOINT, without the port), and the # of TPU cores (derived from ACCELERATOR_TYPE). An ACCELERATOR_TYPE of v3-8 will indicate 8 TPU cores, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud compute tpus list --zone=YOUR_ZONE_HERE_SUCH_AS_us-central1-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update TPU configuration\n",
    "\n",
    "Update the IP address and cores variables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpu_ip_address='10.1.2.3'\n",
    "# tpu_cores=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set TPU environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TPU configuration\n",
    "# %env XRT_TPU_CONFIG=tpu_worker;0;$tpu_ip_address:8470\n",
    "\n",
    "# # Use bfloat16\n",
    "# %env XLA_USE_BF16=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.utilities.xla_device import XLADeviceUtils\n",
    "if XLADeviceUtils.tpu_device_exists():\n",
    "    import torch_xla\n",
    "\n",
    "from trainer.task import train_model\n",
    "from trainer.src.utils import get_datasets\n",
    "\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/VisionTransformers/\")\n",
    "\n",
    "# Setting the seed\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = !nproc\n",
    "# tpu_cores = tpu_cores if 'tpu_cores' in vars() else 0\n",
    "num_cpus = cpu_count()\n",
    "num_gpus = torch.cuda.device_count()\n",
    "device = torch.device('cuda') if num_gpus else 'cpu'\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'CPUs: {num_cpus}')\n",
    "print(f'GPUs: {num_gpus}')\n",
    "# print(f'TPUs: {tpu_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    trainer_num_workers = num_gpus\n",
    "    dataloader_num_workers = num_gpus\n",
    "else:\n",
    "    trainer_num_workers = \"auto\"\n",
    "    dataloader_num_workers = num_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_workers = tpu_cores if 'tpu_cores' in vars() else num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerator = 'tpu' if 'tpu_cores' in vars() else accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(CHECKPOINT_PATH)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(CHECKPOINT_PATH)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'model_kwargs': {\n",
    "    \"embed_dim\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"patch_size\": 4,\n",
    "    \"num_channels\": 3,\n",
    "    \"num_patches\": 64,\n",
    "    \"num_classes\": 10,\n",
    "    \"dropout\": 0.2,\n",
    "},\n",
    "'trainer_kwargs':{\n",
    "    \"default_root_dir\": os.path.join(CHECKPOINT_PATH, \"ViT\"),\n",
    "    \"accelerator\": accelerator,\n",
    "    \"strategy\": \"auto\",\n",
    "    \"devices\": trainer_num_workers,\n",
    "    \"max_epochs\": 25,\n",
    "    \"callbacks\": [\n",
    "        ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\", dirpath=os.path.join(CHECKPOINT_PATH, \"ViT\")),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "    ],\n",
    "},\n",
    "'loader_kwargs':{\n",
    "    \"dataset_path\": DATASET_PATH,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": dataloader_num_workers\n",
    "}}\n",
    "\n",
    "lr=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_set, _ = get_datasets(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "NUM_IMAGES = 4\n",
    "CIFAR_images = torch.stack([val_set[idx][0] for idx in range(NUM_IMAGES)], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(CIFAR_images, nrow=4, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Image examples of the CIFAR10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(**args, lr=3e-4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
